{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Deep Learning with Keras\n",
    "\n",
    "This Jupyter notebook contains code and explanations for the 2018 AIS Intro to Deep Learning workshop.\n",
    "\n",
    "## How to Use This Notebook\n",
    "This notebook has several cells, some with markdown and others with runnable Python code. To run a cell, click on the cell and then use the **SHIFT + ENTER** keyboard shortcut or navigate to **Cell** in the top menu bar and click on **Run Cells** in the dropdown menu.\n",
    "\n",
    "## Software Prerequisites\n",
    "Make sure to install the following software/libraries:\n",
    "\n",
    "- **Anaconda** - Python distribution with many useful libraries\n",
    "- **TensorFlow** - deep learning library, acts as a backend for Keras\n",
    "- **Keras** - a high-level deep learning library that runs on top of TensorFlow\n",
    "\n",
    "## Libraries Used\n",
    "\n",
    "- **Numpy** - for handling linear algebra and numerical computations in machine learning.\n",
    "- **Pandas** - for reading in, preprocessing, and analyzing data.\n",
    "- **SciKit-Learn** - a general-purpose ML library.\n",
    "- **Keras** - features a simple API for deep learning.\n",
    "\n",
    "## About the Dataset - Predicting Income Class Using Census Data\n",
    "The goal of this exercise is to train a neural network to predict whether or not a person earns over $50K per year using information from Census data. This is an example of a **binary classification** problem. The dataset is present in the GitHub repo for this workshop, but can also be found online at the UCI Machine Learning repository: https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Numpy and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "Using Pandas, we can read the dataset from a zipped csv file, and store the data in a dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adult-census-income.zip')\n",
    "data.head() # Displays the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output above, we can see that our dataframe has several columns with information such as the age and education level of different individuals. We can use the **info()** function to get some more information about our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education.num     32561 non-null int64\n",
      "marital.status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "sex               32561 non-null object\n",
      "capital.gain      32561 non-null int64\n",
      "capital.loss      32561 non-null int64\n",
      "hours.per.week    32561 non-null int64\n",
      "native.country    32561 non-null object\n",
      "income            32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Problem - Features vs. Targets \n",
    "Every machine learning problem involves using some variables called **features** to predict single or multiple **targets**. For this problem, based on our data we have a total of **14 features**:\n",
    "- **age**\n",
    "- **workclass**\n",
    "- **fnlwgt**\n",
    "- **education**\n",
    "- **education.num**\n",
    "- **marital status**\n",
    "- **occupation**\n",
    "- **relationship**\n",
    "- **race**\n",
    "- **sex**\n",
    "- **capital.gain**\n",
    "- **capital.loss**\n",
    "- **hours.per.week**\n",
    "- **native.country**\n",
    "\n",
    "Our goal is to train a model that can use these **features** to predict the target value, which is the **income** column. This problem is a **binary classification** column since the target (income) has two possible values: <=50K and > 50K. The income of a given person is either above or below $50K and we want to train a deep learning model to predict this income classification for a person based on the information provided by the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Deep Learning? What are Neural Networks?\n",
    "Deep learning is a subfield of machine learning focused on using biologically-inspired models known as **neural networks** to solve a wide range of machine learning problems. At a high-level, neural networks are basically **mathematical models** that are based roughly on neurological concepts in **human learning**. \n",
    "\n",
    "## The Three Key Components of Neural Networks\n",
    "Neural networks can be a slightly challenging concept to grasp since they involve a mix of ideas from math, computer science, and even neuroscience. There is a lot of technical information in this workshop, so I would recommend focusing on gaining a high-level understanding of **three fundamental components** of neural networks:\n",
    "\n",
    "1. **Structure** - what the neural network looks like, including all the mathematical functions involved, the number of inputs and outputs, and the parameters, called **weights** that the network has to learn.\n",
    "    \n",
    "2. **Loss Function** - a metric that tells us how good or bad the network's predictions are. \n",
    "3. **Optimizer** - the algorithm used for **learning the weights** that give the network the best predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Neural Networks - A Biology and Math Lesson\n",
    "As we mentioned before neural networks are **biologically inspired** models. For a moment, let's forget about machine learning and review how the human nervous system works to understand where the concept of neural networks came from. A **neuron**, the fundamental unit of this system, looks something like this:\n",
    "\n",
    "<img src='neuron.png', width=400px, height=200px>\n",
    "(image source: http://home.agh.edu.pl/~vlsi/AI/intro/)\n",
    "\n",
    "### Key Parts of the Neuron\n",
    "A neuron transmits electrical signals that are constantly activated as the human brain learns and recognizes new concepts. The main parts of a neuron that we should take note of are:\n",
    "\n",
    "- **inputs** - the neuron receives several input signals through **dendrites** from connections to neighboring neurons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Structure of a Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "//anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,051\n",
      "Trainable params: 1,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(14, input_dim=14, activation='sigmoid'))\n",
    "model.add(Dense(28, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Loss Function and Optimizer to the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Our Data for the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HS-grad', 'Some-college', '7th-8th', '10th', 'Doctorate',\n",
       "       'Prof-school', 'Bachelors', 'Masters', '11th', 'Assoc-acdm',\n",
       "       'Assoc-voc', '1st-4th', '5th-6th', '12th', '9th', 'Preschool'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_education(education):\n",
    "    \n",
    "    code_dict = {'Preschool':0,\n",
    "                 '1st-4th': 1,\n",
    "                 '5th-6th': 2,\n",
    "                 '7th-8th': 3,\n",
    "                 '9th': 4,\n",
    "                 '10th': 5,\n",
    "                 '11th': 6,\n",
    "                 '12th': 7,\n",
    "                 'HS-grad': 8,\n",
    "                 'Prof-school': 9,\n",
    "                 'Some-college': 10,\n",
    "                 'Assoc-voc': 11,\n",
    "                 'Assoc-acdm': 12,\n",
    "                 'Bachelors': 13,\n",
    "                 'Masters': 14,\n",
    "                 'Doctorate': 15}\n",
    "    \n",
    "    return code_dict[education]\n",
    "\n",
    "data['education'] = data['education'].apply(encode_education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United-States', '?', 'Mexico', 'Greece', 'Vietnam', 'China',\n",
       "       'Taiwan', 'India', 'Philippines', 'Trinadad&Tobago', 'Canada',\n",
       "       'South', 'Holand-Netherlands', 'Puerto-Rico', 'Poland', 'Iran',\n",
       "       'England', 'Germany', 'Italy', 'Japan', 'Hong', 'Honduras', 'Cuba',\n",
       "       'Ireland', 'Cambodia', 'Peru', 'Nicaragua', 'Dominican-Republic',\n",
       "       'Haiti', 'El-Salvador', 'Hungary', 'Columbia', 'Guatemala',\n",
       "       'Jamaica', 'Ecuador', 'France', 'Yugoslavia', 'Scotland',\n",
       "       'Portugal', 'Laos', 'Thailand', 'Outlying-US(Guam-USVI-etc)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['native.country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null int64\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null int64\n",
      "education.num     32561 non-null int64\n",
      "marital.status    32561 non-null int64\n",
      "occupation        32561 non-null int64\n",
      "relationship      32561 non-null int64\n",
      "race              32561 non-null int64\n",
      "sex               32561 non-null int64\n",
      "capital.gain      32561 non-null int64\n",
      "capital.loss      32561 non-null int64\n",
      "hours.per.week    32561 non-null int64\n",
      "native.country    32561 non-null int64\n",
      "income            32561 non-null int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "object_cols = list(data.select_dtypes(include=['object']))\n",
    "\n",
    "for col in object_cols:\n",
    "    lbl = LabelEncoder()\n",
    "    data[col] = lbl.fit_transform(data[col])\n",
    "\n",
    "\n",
    "#data = pd.get_dummies(data, columns=['workclass', 'marital.status', 'occupation', 'relationship',\n",
    "                                    #'race', 'native.country'])\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = data.drop(['income'], axis=1)\n",
    "y = data['income']\n",
    "for col in X.columns:\n",
    "    scaler = StandardScaler()\n",
    "    X[col] = scaler.fit_transform(X[col].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5514     0\n",
       "19777    0\n",
       "10781    0\n",
       "32240    0\n",
       "9876     0\n",
       "5455     0\n",
       "8615     0\n",
       "29805    1\n",
       "15081    0\n",
       "17203    0\n",
       "9747     1\n",
       "12114    0\n",
       "327      0\n",
       "231      1\n",
       "13770    1\n",
       "5860     0\n",
       "3272     0\n",
       "27240    0\n",
       "24431    0\n",
       "7743     0\n",
       "6951     1\n",
       "21032    0\n",
       "14778    0\n",
       "11423    1\n",
       "26009    1\n",
       "16066    0\n",
       "30825    0\n",
       "10276    0\n",
       "75       1\n",
       "4        0\n",
       "        ..\n",
       "5051     0\n",
       "5311     1\n",
       "2433     1\n",
       "23333    0\n",
       "32157    1\n",
       "30187    0\n",
       "26967    0\n",
       "769      1\n",
       "32052    0\n",
       "1685     1\n",
       "8322     1\n",
       "16023    0\n",
       "27495    1\n",
       "11363    0\n",
       "28020    0\n",
       "14423    0\n",
       "21962    0\n",
       "4426     0\n",
       "29910    1\n",
       "16850    0\n",
       "6265     0\n",
       "22118    0\n",
       "11284    0\n",
       "11964    0\n",
       "21575    0\n",
       "29802    0\n",
       "5390     1\n",
       "860      1\n",
       "15795    1\n",
       "23654    0\n",
       "Name: income, Length: 26048, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26048 samples, validate on 6513 samples\n",
      "Epoch 1/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3229 - acc: 0.8483 - val_loss: 0.3241 - val_acc: 0.8501\n",
      "Epoch 2/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3229 - acc: 0.8469 - val_loss: 0.3235 - val_acc: 0.8505\n",
      "Epoch 3/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3220 - acc: 0.8482 - val_loss: 0.3243 - val_acc: 0.8475\n",
      "Epoch 4/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3215 - acc: 0.8477 - val_loss: 0.3229 - val_acc: 0.8492\n",
      "Epoch 5/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3212 - acc: 0.8481 - val_loss: 0.3233 - val_acc: 0.8505\n",
      "Epoch 6/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3207 - acc: 0.8480 - val_loss: 0.3272 - val_acc: 0.8477\n",
      "Epoch 7/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3203 - acc: 0.8494 - val_loss: 0.3240 - val_acc: 0.8471\n",
      "Epoch 8/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3200 - acc: 0.8493 - val_loss: 0.3214 - val_acc: 0.8514\n",
      "Epoch 9/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3195 - acc: 0.8499 - val_loss: 0.3215 - val_acc: 0.8492\n",
      "Epoch 10/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3190 - acc: 0.8494 - val_loss: 0.3215 - val_acc: 0.8511\n",
      "Epoch 11/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3189 - acc: 0.8495 - val_loss: 0.3211 - val_acc: 0.8503\n",
      "Epoch 12/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3186 - acc: 0.8500 - val_loss: 0.3200 - val_acc: 0.8521\n",
      "Epoch 13/15\n",
      "26048/26048 [==============================] - 0s - loss: 0.3178 - acc: 0.8506 - val_loss: 0.3207 - val_acc: 0.8503\n",
      "Epoch 14/15\n",
      "26048/26048 [==============================] - 1s - loss: 0.3176 - acc: 0.8502 - val_loss: 0.3260 - val_acc: 0.8475\n",
      "Epoch 15/15\n",
      "26048/26048 [==============================] - 1s - loss: 0.3180 - acc: 0.8496 - val_loss: 0.3210 - val_acc: 0.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12373b4e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, y_train, validation_data=(X_test.values, y_test), epochs=15, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
